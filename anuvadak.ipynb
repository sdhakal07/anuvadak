{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEiDlXiQcFS9"
   },
   "source": [
    "# English to Nepali translation using Transformer Based Model\n",
    "\n",
    "This notebook builds a basic **Encoder-Decoder** variant of the Transformer architecture from scratch (Multi-Head Attention, Scaled Dot-Product Attention and Causal Masking included) in TensorFlow.\n",
    "\n",
    "It serves to understand how each part of the Transformer works and how they all fit together.\n",
    "\n",
    "The Transformer is then tested on a simple seq2seq task : **translating sentences from English to Nepali**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cLFegv5fcFTA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGOB9mWXcFTC",
    "outputId": "1aa8c19c-fcf1-4a42-f3dd-30768d9015b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor Flow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBlWu_vucFTD",
    "outputId": "cc659ef1-e01b-4054-aa77-a7c9154328e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPU: {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gf3ppQaOcexi",
    "outputId": "d9ec881c-42ab-4517-cb87-86388edc30e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: C:\\Users\\Leapfrog\\Downloads\n"
     ]
    }
   ],
   "source": [
    "print(f\"current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZ4qOz6BcFTD"
   },
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cbY_O-KcFTD"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Reading the data</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "bCCO-9yEcFTE",
    "outputId": "4c7facd3-5cda-4252-cc25-2183fe1e2125"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>Nepali words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26606</th>\n",
       "      <td>If I fought with animals at Ephesus for human ...</td>\n",
       "      <td>यदि खाली मानवताको कारणले मैले एफिससमा जंगली जा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10481</th>\n",
       "      <td>Let the proud be disappointed, for they have o...</td>\n",
       "      <td>मानिसहरू ज-जसले तिनीहरू मभन्दा असल हुँ भनेर सो...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36039</th>\n",
       "      <td>But the strength of the translation and the sk...</td>\n",
       "      <td>तर अनुवादको सशक्तता तथा साहित्यिक अनुवादको सीप...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130069</th>\n",
       "      <td>People of this kind of microscopic illness and...</td>\n",
       "      <td>यस किसिमको भष्म धातुक्षयका बिरामी तथा दुर्बलता...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66250</th>\n",
       "      <td>Windows Scheme (With Win Key)</td>\n",
       "      <td>विण्डोज योजना (विन कुञ्जीसँग)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142925</th>\n",
       "      <td>Insert Label Ranges</td>\n",
       "      <td>लेबल फैलावट जोड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103645</th>\n",
       "      <td>Therefore , no development , research and diss...</td>\n",
       "      <td>त्यसैले , सिमलत्तरुल सम्बन्धी कुनै बिकास , अनु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>also the firstborn of our sons, and of our liv...</td>\n",
       "      <td>“व्यवस्थामा लेखे झैं हामी पनि हाम्रा पहिलो जन्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46256</th>\n",
       "      <td>Click here to remove the selected file type.</td>\n",
       "      <td>चयन गरेको फाइल प्रकार हटाउन यहाँ क्लिक गर्नुहो...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145898</th>\n",
       "      <td>Try to Reattempt a Download</td>\n",
       "      <td>डाउनलोडका निम्ति फेरि प्रयास गर्नुहोस्</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  English words/sentences  \\\n",
       "26606   If I fought with animals at Ephesus for human ...   \n",
       "10481   Let the proud be disappointed, for they have o...   \n",
       "36039   But the strength of the translation and the sk...   \n",
       "130069  People of this kind of microscopic illness and...   \n",
       "66250                       Windows Scheme (With Win Key)   \n",
       "142925                                Insert Label Ranges   \n",
       "103645  Therefore , no development , research and diss...   \n",
       "7142    also the firstborn of our sons, and of our liv...   \n",
       "46256        Click here to remove the selected file type.   \n",
       "145898                        Try to Reattempt a Download   \n",
       "\n",
       "                                   Nepali words/sentences  \n",
       "26606   यदि खाली मानवताको कारणले मैले एफिससमा जंगली जा...  \n",
       "10481   मानिसहरू ज-जसले तिनीहरू मभन्दा असल हुँ भनेर सो...  \n",
       "36039   तर अनुवादको सशक्तता तथा साहित्यिक अनुवादको सीप...  \n",
       "130069  यस किसिमको भष्म धातुक्षयका बिरामी तथा दुर्बलता...  \n",
       "66250                      विण्डोज योजना (विन कुञ्जीसँग)   \n",
       "142925                                    लेबल फैलावट जोड  \n",
       "103645  त्यसैले , सिमलत्तरुल सम्बन्धी कुनै बिकास , अनु...  \n",
       "7142    “व्यवस्थामा लेखे झैं हामी पनि हाम्रा पहिलो जन्...  \n",
       "46256   चयन गरेको फाइल प्रकार हटाउन यहाँ क्लिक गर्नुहो...  \n",
       "145898             डाउनलोडका निम्ति फेरि प्रयास गर्नुहोस्  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the file path\n",
    "file_path = os.path.join(os.getcwd(), r\"C:\\Users\\Leapfrog\\Desktop\\Final Anuvadak\\dataset_latest.csv\")\n",
    "\n",
    "# Reading txt file\n",
    "# with open(file_path, \"rb\") as f:\n",
    "#     data=f.read()\n",
    "\n",
    "# Decode the bytes object to a string, assuming UTF-8 encoding\n",
    "# data = data.decode('utf-8')  # This line is added to decode the bytes object\n",
    "\n",
    "# Creating a DataFrame\n",
    "# df = pd.DataFrame([line.split('\\t')[:2] for line in data.strip().split('\\n')], columns=[\"English words/sentences\", \"Nepali words/sentences\"])\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "df.rename(columns={\"source\": \"English words/sentences\", \"target\": \"Nepali words/sentences\"}, inplace=True)\n",
    "\n",
    "# Printing the dataframe\n",
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "7UEyYMdGcFTE",
    "outputId": "8aa5f76e-4851-4573-c459-3a68e9b5f0ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110412</th>\n",
       "      <td>First World War, DDT prayogadosro poisonous in...</td>\n",
       "      <td>[start] सर्वप्रथम डीडीटीको प्रयोगदोस्रो विश्वय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18587</th>\n",
       "      <td>In the first day there shall be to you a holy ...</td>\n",
       "      <td>[start] यो पवित्र चाडको पहिलो र अन्तिम दिनमा प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40590</th>\n",
       "      <td>Agfa Pan 100: Simulate the Agfa Pan black and ...</td>\n",
       "      <td>[start] तटस्थ श्यामश्वेतश्यामश्वेत तटस्थ फिल्म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127844</th>\n",
       "      <td>She says - ' Because of not being educated acc...</td>\n",
       "      <td>[start] उनी भन्छिन् – ‘ पढाइअनुसारको मान्यता न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49104</th>\n",
       "      <td>Create a new unit from scratch</td>\n",
       "      <td>[start] स्क्रयाचबाट नयाँ एकाइ सिर्जना गर्नुहोस...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107789</th>\n",
       "      <td>What does this benefit me ?</td>\n",
       "      <td>[start] यसले मलाई के लाभ हुन्छ र ? [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116424</th>\n",
       "      <td>The ground - Part overworked.</td>\n",
       "      <td>[start] ती भू-भाग जोतिए । [end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124786</th>\n",
       "      <td>Lascar of the women who are increasingly blowi...</td>\n",
       "      <td>[start] बागलुङ सखारै उकालिदै गरेका महिलाको लस्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100327</th>\n",
       "      <td>Real Sukkur residents do not know that land is...</td>\n",
       "      <td>[start] वास्तविक सुकुम्वासीलाई त जग्गा पाईन्छ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90156</th>\n",
       "      <td>Editor text formating</td>\n",
       "      <td>[start] सम्पादकको पाठ ढाँचाबद्ध गर्दैछ [end]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   source  \\\n",
       "110412  First World War, DDT prayogadosro poisonous in...   \n",
       "18587   In the first day there shall be to you a holy ...   \n",
       "40590   Agfa Pan 100: Simulate the Agfa Pan black and ...   \n",
       "127844  She says - ' Because of not being educated acc...   \n",
       "49104                      Create a new unit from scratch   \n",
       "107789                        What does this benefit me ?   \n",
       "116424                      The ground - Part overworked.   \n",
       "124786  Lascar of the women who are increasingly blowi...   \n",
       "100327  Real Sukkur residents do not know that land is...   \n",
       "90156                               Editor text formating   \n",
       "\n",
       "                                                   target  \n",
       "110412  [start] सर्वप्रथम डीडीटीको प्रयोगदोस्रो विश्वय...  \n",
       "18587   [start] यो पवित्र चाडको पहिलो र अन्तिम दिनमा प...  \n",
       "40590   [start] तटस्थ श्यामश्वेतश्यामश्वेत तटस्थ फिल्म...  \n",
       "127844  [start] उनी भन्छिन् – ‘ पढाइअनुसारको मान्यता न...  \n",
       "49104   [start] स्क्रयाचबाट नयाँ एकाइ सिर्जना गर्नुहोस...  \n",
       "107789           [start] यसले मलाई के लाभ हुन्छ र ? [end]  \n",
       "116424                    [start] ती भू-भाग जोतिए । [end]  \n",
       "124786  [start] बागलुङ सखारै उकालिदै गरेका महिलाको लस्...  \n",
       "100327  [start] वास्तविक सुकुम्वासीलाई त जग्गा पाईन्छ ...  \n",
       "90156        [start] सम्पादकको पाठ ढाँचाबद्ध गर्दैछ [end]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source\"] = df[\"English words/sentences\"]\n",
    "\n",
    "# let's add an initial “seed” token ([start]) and a stop token ([end]) to each target sentence.\n",
    "df[\"target\"] = df[\"Nepali words/sentences\"].apply(lambda x: \"[start] \" + x + \" [end]\")\n",
    "df = df.drop([\"English words/sentences\", \"Nepali words/sentences\"], axis=1)\n",
    "\n",
    "# display a few random samples\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZn4g9RIiyz0",
    "outputId": "f1c784f9-b0a6-4551-a840-cb8617f55f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: 146901\n"
     ]
    }
   ],
   "source": [
    "# df = df.sample(100000)\n",
    "\n",
    "print(f\"Total dataset: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D6mcCQecFTF"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Shuffling the data and splitting it into train, validation, and test sets</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "kgUf2wiOcFTG",
    "outputId": "3037f4ed-e214-4504-a8f9-a32744a665a2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# split the data into train, validation, and test sets\n",
    "train_size = int(len(df) * 0.7)\n",
    "val_size = int(len(df) * 0.2)\n",
    "test_size = int(len(df) * 0.1)\n",
    "\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:train_size+val_size]\n",
    "test_df = df[train_size+val_size:]\n",
    "\n",
    "# display the data sets representations using a pie chart just to see the distribution of the data\n",
    "labels = \"Train\", \"Validation\", \"Test\"\n",
    "sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "explode = (0.1, 0, 0)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct=\"%1.1f%%\", shadow=True, startangle=90)\n",
    "ax1.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0trBi9M0cFTG"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Standardizing, tokenizing and indexing the data</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKrY-mndcFTG"
   },
   "source": [
    "First, we need to parse our raw text data and vectorize it.\n",
    "\n",
    "To keep things simple, we will first limit our vocabulary using the **max_tokens** parameter. We will also limit the length of each sentence using the **sequence_length** parameter.\n",
    "\n",
    "Each sentence will be standardized, tokenized by word, and then indexed by token.\n",
    "\n",
    "This will result in a batch of vectors of tokens, stored in a **2D** matrix of shape [(batch_size, **sequence_length**)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YfEw9MvdcFTG"
   },
   "outputs": [],
   "source": [
    "max_tokens = 2500\n",
    "sequence_length = 30\n",
    "\n",
    "# define a custom standardization function that convert to lowercase and strips all punctuations except \"[\" and \"]\" (so we can tell apart \"start\" from \"[start]\").\n",
    "strip_chars = string.punctuation\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "# tokenize the data using our custom standardization function\n",
    "source_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1, # add +1 token to our target sentences since they'll be shifted right by 1 during training\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "def sanitize_text(text):\n",
    "    return text.encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "\n",
    "\n",
    "# index all tokens in the source and target sentences\n",
    "train_source_texts = train_df[\"source\"].astype(str).values\n",
    "train_target_texts = train_df[\"target\"].apply(sanitize_text).astype(str).values\n",
    "source_vectorization.adapt(train_source_texts)\n",
    "target_vectorization.adapt(train_target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[start] @LuisCarlos आफ्नो बाईकमा छन्, तर साँझ ५:३० देखि उनी संपर्कमा छैनन् र  [end]'\n",
      " '[start] सबै छविहरू अधिलेखन गर्नुहोस् [end]']\n"
     ]
    }
   ],
   "source": [
    "print(train_target_texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5_aQO0mmcFTH"
   },
   "outputs": [],
   "source": [
    "\n",
    "# display a random sample before and after vectorization just to test the vectorization\n",
    "random_sample = random.randint(0, len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67944\n"
     ]
    }
   ],
   "source": [
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beJm9pUgcFTH",
    "outputId": "e6bd7e15-3533-4261-ff64-ff523b80c207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source decoded texts (one random sample): [UNK] to                             \n"
     ]
    }
   ],
   "source": [
    "# display the decoding of the vectorized text (from vector back to text) just to test the vectorization\n",
    "source_decoded_text = \"\"\n",
    "for i in range(len(source_vectorization(train_source_texts[random_sample]))):\n",
    "    source_decoded_text += source_vectorization.get_vocabulary()[source_vectorization(train_source_texts[random_sample])[i]] + ' '\n",
    "print(\"Source decoded texts (one random sample):\", source_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMVq8amXcFTH",
    "outputId": "284c5547-954d-47a3-a6d6-117fcc0639e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source texts (one random sample): Redirecting to...\n"
     ]
    }
   ],
   "source": [
    "print(\"Source texts (one random sample):\", train_source_texts[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YPEzKeFcFTH",
    "outputId": "cf3bab7c-3ada-429c-9316-0b60118ef0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target texts (one random sample): [start] लाई पुननिर्देशन गरिँदैछ... [end]\n"
     ]
    }
   ],
   "source": [
    "print(\"Target texts (one random sample):\", train_target_texts[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tESaa3NgcFTI",
    "outputId": "5ae6e055-fc95-433c-9b2f-84ca8707e562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source vectors (one random sample): tf.Tensor([1 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(30,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2u4YsbncFTI",
    "outputId": "9841fa22-b12a-422a-c004-0d6fb75636bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target vectors (one random sample): tf.Tensor(\n",
      "[  2 271   1   1   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(31,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Target vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8785\n"
     ]
    }
   ],
   "source": [
    "random_sample = random.randint(0, len(train_target_texts) - 1)  # Ensure random_sample is valid\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36531\n"
     ]
    }
   ],
   "source": [
    "target_decoded_text = \"\"\n",
    "random_sample = random.randint(0, len(train_target_texts) - 1)  # Ensure random_sample is valid\n",
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(target_vectorization(train_target_texts[random_sample])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] तर रिसर्च सेन्टरको बोर्ड राखेका साना क्लिनिकले भने कुनै अध्ययन – अनुसन्धान गर्न सकेका छैनन् । [end]\n"
     ]
    }
   ],
   "source": [
    "print(train_target_texts[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36531\n"
     ]
    }
   ],
   "source": [
    "print(random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(68, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vocab_index = target_vectorization(train_target_texts[77065])[1]\n",
    "print(vocab_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_surrogates(s):\n",
    "    return any(0xD800 <= ord(c) <= 0xDFFF for c in s)\n",
    "\n",
    "invalid_texts = [text for text in train_df[\"target\"] if has_surrogates(text)]\n",
    "if invalid_texts:\n",
    "    print(\"Found texts with surrogates. Clean the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXuv1R3ocFTI",
    "outputId": "11cc7066-e9ac-4d80-cbe0-9d312f420d0b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m target_decoded_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m random_sample \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_target_texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure random_sample is valid\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target_vectorization(train_target_texts[random_sample]))):\n\u001b[0;32m      5\u001b[0m     vocab_index \u001b[38;5;241m=\u001b[39m target_vectorization(train_target_texts[random_sample])[i]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "target_decoded_text = \"\"\n",
    "random_sample = random.randint(0, len(train_target_texts) - 1)  # Ensure random_sample is valid\n",
    "\n",
    "for i in range(len(target_vectorization(train_target_texts[random_sample]))):\n",
    "    vocab_index = target_vectorization(train_target_texts[random_sample])[i]\n",
    "    target_decoded_text += target_vectorization.get_vocabulary()[vocab_index] + \" \"\n",
    "\n",
    "print(\"Target decoded texts (one random sample):\", target_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Ensure random_sample is valid\n",
    "random_sample = random.randint(0, len(train_target_texts) - 1)\n",
    "\n",
    "# Vectorize the randomly selected target text\n",
    "vectorized_text = target_vectorization(train_target_texts[random_sample])\n",
    "\n",
    "# Decode the vectorized text\n",
    "target_decoded_text = \"\"\n",
    "vocabulary = target_vectorization.get_vocabulary()\n",
    "\n",
    "for vocab_index in vectorized_text:\n",
    "    try:\n",
    "        word = vocabulary[vocab_index]\n",
    "        if isinstance(word, bytes):\n",
    "            word = word.decode(\"utf-8\", errors=\"replace\")  # Replace invalid characters\n",
    "        target_decoded_text += word + \" \"\n",
    "    except UnicodeError as e:\n",
    "        print(f\"Error decoding vocabulary entry at index {vocab_index}: {e}\")\n",
    "        target_decoded_text += \"[UNK] \"  # Use a placeholder for corrupted entries\n",
    "\n",
    "# Remove the trailing space\n",
    "target_decoded_text = target_decoded_text.strip()\n",
    "\n",
    "print(\"Target decoded texts (one random sample):\", target_decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSNbsq1bcFTI",
    "outputId": "8764542e-cc3c-4fb7-dbac-85c15adbd425"
   },
   "outputs": [],
   "source": [
    "# display the shape of our vectorized data\n",
    "train_source_vectors = source_vectorization(train_source_texts)\n",
    "train_target_vectors = target_vectorization(train_target_texts)\n",
    "print(\"Source vectors (shape):\", train_source_vectors.shape)\n",
    "print(\"Target vectors (shape):\", train_target_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsTtDtRPcFTI"
   },
   "source": [
    "# Building the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPrMokOVcFTI"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Positional Embedding</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C1yHZ_EcFTI"
   },
   "source": [
    "In order for our Transformer to be aware of the word order in each sentence, we must add some positional information to the data. **Words must become position-aware.**\n",
    "\n",
    "First, each token in our vectors will be embedded in a low-dimensional vector (the dimensionality of the embedding space is defined by the **embedding_size** parameter).\n",
    "\n",
    "Secondly, position information (info on where each word stands in the sentence) will be created and added to the embeddings.\n",
    "\n",
    "This will result in a batch of vectors of positional embeddings, stored in a **3D** matrix of shape [(batch_size, sequence_length, **embedding_size**)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVgTp7PIcFTJ"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim) # token embedding layer\n",
    "        self.position_embeddings = keras.layers.Embedding(input_dim=sequence_length, output_dim=output_dim) # position embedding layer\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        embedded_tokens = self.token_embeddings(inputs) # embed the tokens\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1) # create the positional information\n",
    "        embedded_positions = self.position_embeddings(positions) # embed the positions\n",
    "        return embedded_tokens + embedded_positions # add the token and position embeddings to create the positional embeddings\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return keras.ops.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nDqwD09cFTJ",
    "outputId": "71803a32-dae1-4b12-f8d8-397589fc9da3"
   },
   "outputs": [],
   "source": [
    "# display a random sample before and after embbeding just to test our class\n",
    "\n",
    "embed_dim = 256\n",
    "\n",
    "with tf.device('gpu:0'):\n",
    "    train_source_embedded = PositionalEmbedding(\n",
    "        sequence_length=sequence_length,\n",
    "        input_dim=max_tokens,\n",
    "        output_dim=embed_dim,\n",
    "        name=\"source_embedding\",\n",
    "    ) (train_source_vectors)\n",
    "\n",
    "    train_target_embedded = PositionalEmbedding(\n",
    "        sequence_length=sequence_length,\n",
    "        input_dim=max_tokens,\n",
    "        output_dim=embed_dim,\n",
    "        name=\"target_embedding\",\n",
    "    ) (train_source_vectors)\n",
    "\n",
    "    random_sample = random.randint(0, len(train_df))\n",
    "    print(\"Source texts (one random sample):\", train_source_texts[random_sample])\n",
    "    print(\"\\nTarget texts (one random sample):\", train_target_texts[random_sample])\n",
    "    print(\"\\nSource vectors (one random sample):\", source_vectorization(train_source_texts[random_sample]))\n",
    "    print(\"\\nTarget vectors (one random sample):\", target_vectorization(train_target_texts[random_sample]))\n",
    "    print(\"\\nSource embedded vectors (one random sample):\", train_source_embedded[random_sample])\n",
    "    print(\"\\nTarget embedded vectors (one random sample):\", train_target_embedded[random_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuvpCR3rcFTJ",
    "outputId": "fb64904f-f0a4-413c-b155-6c790e2a52d7"
   },
   "outputs": [],
   "source": [
    "# display the shape of our embedded data just to test the class\n",
    "print(\"Source embedded vectors (shape):\", train_source_embedded.shape)\n",
    "print(\"Target embedded vectors (shape):\", train_target_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcPWncjecFTJ"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>The Attention mechanism</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlI3cnY-cFTJ"
   },
   "source": [
    "The goal here is to make each of our words (positional embeddings at this point) aware of the other words surrounding them. **Words must become context-aware.**\n",
    "\n",
    "The implementation of the Attention mechanism involves the following 3 steps :\n",
    "\n",
    "- Causal Masking\n",
    "- Scaled Dot-Product Attention\n",
    "- Multi-Head Attention\n",
    "\n",
    "In practice, we could just use **keras.layers.MultiHeadAttention** instead of building it from scratch, but let's do it anyway!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C5ILP58cFTJ"
   },
   "source": [
    "<div style=\"color:#fff; display:fill; border-width:1px; border-color:#000; font-size:125%;\">\n",
    "    <p style=\"border-style:solid; border-radius:8px; background-color:#fff; padding: 8px 12px 8px 12px; color:#000;\"><b>Causal Masking</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loAnZbxacFTJ"
   },
   "source": [
    "\n",
    "Since our words will now be context-aware (aware of words before **and** after them in the sentence), we need a way to mask those *after-words* when needed be (i.e. during training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiORUaihcFTK"
   },
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "def attention_mask(nd, ns, *, dtype):\n",
    "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
    "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
    "    \"\"\"\n",
    "    i = tf.range(nd)[:,None]\n",
    "    j = tf.range(ns)\n",
    "    m = i >= j - ns + nd\n",
    "    return tf.cast(m, dtype)\n",
    "\n",
    "def mask_attn_weights(w):\n",
    "    # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
    "    _, _, nd, ns = shape_list(w)\n",
    "    b = attention_mask(nd, ns, dtype=w.dtype)\n",
    "    b = tf.reshape(b, [1, 1, nd, ns])\n",
    "    w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tzyU8DgcFTK",
    "outputId": "9c62edd2-0ee5-4c50-dba4-65690b7993b9"
   },
   "outputs": [],
   "source": [
    "# display the causal masking of a random tensor just to test the function\n",
    "random_tensor = tf.random.uniform(shape=(1, 1, 5, 5), minval=0, maxval=1, dtype=tf.float32)\n",
    "print(\"Masked attention weights:\", mask_attn_weights(random_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0-OrVe6cFTK"
   },
   "source": [
    "<div style=\"color:#fff; display:fill; border-width:1px; border-color:#000; font-size:125%;\">\n",
    "    <p style=\"border-style:solid; border-radius:8px; background-color:#fff; padding: 8px 12px 8px 12px; color:#000;\"><b>Scaled Dot-Product Attention</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn55MD4TcFTK"
   },
   "source": [
    "This function is what makes our words context-aware.\n",
    "\n",
    "We want to compare each word with every other words around them and take note of how *related* they are. Technically, this process can be described as \"mapping a query and a set of key-value pairs to an output\". It can be summarized as follows :\n",
    "- We take a **Q**uery of elements.\n",
    "- For each element in the **Q**uery, we score how much that element is related to every **K**ey (This is done using a compatibility function : MatMul). If needed be, Causal Masking will be applied here.\n",
    "- Then, we use these relationship scores to weight a sum of **V**alues, which will be our new context-aware representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvjFOTZYcFTK"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, use_causal_mask=False):\n",
    "    d_k = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scores = tf.matmul(q, k, transpose_b=True) # Matmul of Q and K\n",
    "    scaled_scores = scores / tf.math.sqrt(d_k) # Scale\n",
    "    if use_causal_mask:\n",
    "        scaled_scores = mask_attn_weights(scaled_scores) # Mask (opt.)\n",
    "    weights = tf.nn.softmax(scaled_scores, axis=-1) # SoftMax\n",
    "    output = tf.matmul(weights, v) # Matmul of SoftMax and V\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXm_7ys5cFTL",
    "outputId": "c5e3b5b9-41e7-417e-87d6-278a1a446643"
   },
   "outputs": [],
   "source": [
    "# display the shape of our attention output just to test the function\n",
    "\n",
    "input = train_source_embedded\n",
    "input = tf.expand_dims(input, axis=1)\n",
    "print(\"Scaled dot product attention (shape):\", scaled_dot_product_attention(input, input, input, use_causal_mask=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4iM6sT-cFTL"
   },
   "source": [
    "<div style=\"color:#fff; display:fill; border-width:1px; border-color:#000; font-size:125%;\">\n",
    "    <p style=\"border-style:solid; border-radius:8px; background-color:#fff; padding: 8px 12px 8px 12px; color:#000;\"><b>Multi-Head Attention</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VWoF_6HcFTL"
   },
   "source": [
    "Multi-head attention was introduced in [Attention is all you need](https://arxiv.org/abs/1706.03762) and is wayyy to technical for me to try and explain here. But basically, it allows for multiple Scaled Dot-Production Attention functions to be run in parallel.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLwGbWifcFTN"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, h, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.h = h\n",
    "        if embed_dim % h != 0:\n",
    "            raise ValueError(\n",
    "                f\"dimension of the embedding space = {embed_dim} should be divisible by number of heads = {h}\"\n",
    "            )\n",
    "        self.q_linear = keras.layers.Dense(embed_dim)\n",
    "        self.k_linear = keras.layers.Dense(embed_dim)\n",
    "        self.v_linear = keras.layers.Dense(embed_dim)\n",
    "        self.concat_linear = keras.layers.Dense(embed_dim)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, shape=(batch_size, -1, self.h, self.embed_dim // self.h))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def concat_heads(self, x, batch_size):\n",
    "        x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(x, (batch_size, -1, self.embed_dim))\n",
    "\n",
    "    def call(self, q, k, v, use_causal_mask=False):\n",
    "        batch_size = tf.shape(k)[0]\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        attention = scaled_dot_product_attention(q, k, v, use_causal_mask)\n",
    "        concat = self.concat_heads(attention, batch_size)\n",
    "        concat = self.concat_linear(concat)\n",
    "        return concat\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttention, self).get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"h\": self.h,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xffQuSfBcFTO"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>The Encoder</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W_qem_NcFTO"
   },
   "source": [
    "The role of the Encoder is to process the source sentence. Here, no Causal Masking is needed : information is allowed to flow in both directions (words can be aware of words before **and** after them in the sentence).\n",
    "\n",
    "The Encoder's a pretty generic module that ingests a sentence and learns to turn it into a more useful representation. It can also be used by itself (without the Decoder) for Natural Language Understanding (NLU) tasks like Classification or Named Entity Recognition (NER).\n",
    "\n",
    "In the Encoder's Multi-Head Self-Attention layer ([Global self-attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_global_self_attention_layer)), the **Source Vectors Embeddings** are being passed to all three parameters : **Q**uery, **K**ey, and **V**alue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW9YkAeccFTO"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.global_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.global_self_attention(q=x, k=x, v=x))\n",
    "        x = self.layer_norm_2(x + self.feed_forward(x))\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNbdiaF0cFTO"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>The Decoder</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laMYQcfxcFTO"
   },
   "source": [
    "The role of the Decoder is to look at the target sentence so far and predict the next word in that sentence.\n",
    "\n",
    "Contrary to the Encoder, the Decoder is made of two Attention layers. The first Attention layer does a similar job as the Encoder's sole Attention layer, with the important distinction that here, Causal Masking is enabled because, to correctly train our Transformer to predict the next word based on the current word and the previous words in the sentence, we need to mask the *after-words*. Meanwhile, The second Attention layer is much more straight-forward and basically just acts as a bridge that connects the Encoder to the Decoder.\n",
    "\n",
    "In the Decoder's first Attention layer, the Masked Multi-Head Self-Attention layer ([Causal self-attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_causal_self_attention_layer)), the **Target Vectors Embeddings** are being passed to all three parameters : **Q**uery, **K**ey, and **V**alue. Like mentionned above, Causal Masking is enabled in this layer.\n",
    "\n",
    "In the Decoder's second Attention layer, the Encoder-Decoder Attention layer ([Cross attention layer](https://www.tensorflow.org/text/tutorials/transformer#the_cross_attention_layer)), the **outputs of the Encoder** are being passed to the **K**ey and **V**alue parameters, with the **outputs of the Decoder's Masked Multi-Head Self-Attention layer** being passed to the **Q**uery parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB6YsF3jcFTO"
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.causal_self_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.cross_attention = MultiHeadAttention(embed_dim=embed_dim, h=num_heads)\n",
    "        self.feed_forward = keras.Sequential(\n",
    "            [keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layer_norm_1 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_2 = keras.layers.LayerNormalization()\n",
    "        self.layer_norm_3 = keras.layers.LayerNormalization()\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, x, context):\n",
    "        # Post layer normalization + residual connections\n",
    "        x = self.layer_norm_1(x + self.causal_self_attention(q=x, k=x, v=x, use_causal_mask=True))\n",
    "        x = self.layer_norm_2(x + self.cross_attention(q=x, k=context, v=context))\n",
    "        x = self.layer_norm_3(x + self.feed_forward(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NedehwP9cFTP"
   },
   "source": [
    "<div style=\"color:#000; display:fill; border-radius:8px; background-color:#000; font-size:125%;\">\n",
    "    <p style=\"padding: 8px 12px 8px 12px; color:#fff;\"><b>Putting it all together</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWR39nGecFTP"
   },
   "source": [
    "We  turn our data into a *tf.data pipeline* that returns a tuple (Inputs, Outputs) where Inputs is a dict with two keys : **encoder_inputs** (the source sentence) and **decoder_inputs** (the target sentence), and Outputs is a single key : **decoder_outputs** (the target sentence \"shifted right\").\n",
    "\n",
    "During training, the fact that our Outputs are offset by one step ahead (\"shifted right\"), combined with the Causal Masking of the Decoder (Masked Multi-Head Attention layer), ensures that the\n",
    "predictions for position *i* can depend only on the known outputs at positions less than *i* (no *after-words* visible).\n",
    "\n",
    "During inference, we'll generate one target word at a time and then feed it back into the Decoder so that it can predict the next word. And so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UESTfTBTcFTP"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(source, target):\n",
    "    source_vectors = source_vectorization(source)\n",
    "    target_vectors = target_vectorization(target)\n",
    "    return ({\n",
    "        \"source\": source_vectors, # encoder_inputs\n",
    "        \"target\": target_vectors[:, :-1], # decoder_inputs (truncate by 1 to keep it at the same length as decoder_outputs, which is shifted right by 1).\n",
    "    }, target_vectors[:, 1:]) # decoder_outputs\n",
    "\n",
    "def make_dataset(df):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((df[\"source\"].astype(\"str\").values, df[\"target\"].astype(\"str\").values))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_df)\n",
    "val_ds = make_dataset(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJF1bwyfcFTP",
    "outputId": "1baccc3c-6705-4226-de1a-4d5ccf359afc"
   },
   "outputs": [],
   "source": [
    "# display the shape of the first batch of data in the dataset just to see what it looks like\n",
    "for batch in train_ds.take(1):\n",
    "    print(\"Encoder Inputs:\", batch[0][\"source\"].shape)\n",
    "    print(\"Decoder Inputs:\", batch[0][\"target\"].shape)\n",
    "    print(\"Decoder Outputs:\", batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmWg4zuxcFTP",
    "outputId": "6184ab55-ecf1-4fa3-907f-d2ca8cc66a94"
   },
   "outputs": [],
   "source": [
    "embed_dim = 512 # dimension of the embedding space\n",
    "dense_dim = 2048 # dimension of the feed forward network (a rule of thumb is to use 4 times the size of the embeddings)\n",
    "num_heads = 8\n",
    "\n",
    "with tf.device('gpu:0'):\n",
    "  # the transformer body\n",
    "  encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "  x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "  encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "  decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "  x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "  x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "  # the transformer body\n",
    "  # encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "  # x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "\n",
    "  # # Add more encoder layers\n",
    "  # num_encoder_layers = 3  # You can change this number\n",
    "  # for _ in range(num_encoder_layers):\n",
    "  #     x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "  # encoder_outputs = x  # Output of the last encoder layer\n",
    "\n",
    "  # decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "  # x = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "\n",
    "  # # Add more decoder layers\n",
    "  # num_decoder_layers = 3  # You can change this number\n",
    "  # for _ in range(num_decoder_layers):\n",
    "  #     x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "\n",
    "  # the transformer head\n",
    "  x = keras.layers.Dropout(0.5)(x)\n",
    "  decoder_outputs = keras.layers.Dense(max_tokens, activation=\"softmax\")(x)\n",
    "\n",
    "  transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0BSQhtlQXk_l"
   },
   "outputs": [],
   "source": [
    "# # Define hyperparameters\n",
    "# embed_dim = 512  # Dimension of the embedding space\n",
    "# dense_dim = 2048  # Dimension of the feedforward network\n",
    "# num_heads = 8  # Number of attention heads\n",
    "# num_encoder_layers = 6  # Number of encoder layers\n",
    "# num_decoder_layers = 6  # Number of decoder layers\n",
    "# dropout_rate = 0.5  # Dropout rate\n",
    "\n",
    "# # Inputs for encoder and decoder\n",
    "# encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"source\")\n",
    "# decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"target\")\n",
    "\n",
    "# # Positional embedding\n",
    "# x_encoder = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(encoder_inputs)\n",
    "# x_decoder = PositionalEmbedding(sequence_length, max_tokens, embed_dim)(decoder_inputs)\n",
    "\n",
    "# # Encoder stack\n",
    "# for _ in range(num_encoder_layers):\n",
    "#     x_encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)(x_encoder)\n",
    "# encoder_outputs = x_encoder\n",
    "\n",
    "# # Decoder stack\n",
    "# for _ in range(num_decoder_layers):\n",
    "#     x_decoder = TransformerDecoder(embed_dim, dense_dim, num_heads)(x_decoder, encoder_outputs)\n",
    "\n",
    "# # Output head\n",
    "# x_decoder = keras.layers.Dropout(dropout_rate)(x_decoder)\n",
    "# decoder_outputs = keras.layers.Dense(max_tokens, activation=\"softmax\")(x_decoder)\n",
    "\n",
    "# # Define the complete Transformer model\n",
    "# transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# # Summary of the model\n",
    "# transformer.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5NdIQ_McFTP"
   },
   "source": [
    "# Training the Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ra7b_y0TcFTQ"
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# transformer.compile(\n",
    "#     optimizer=\"rmsprop\",\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"])\n",
    "\n",
    "# EPOCHS = 15\n",
    "# # checkpoint_filepath = '/tmp/checkpoint.weights.h5'\n",
    "# callbacks_list = [\n",
    "#     keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor='val_loss',\n",
    "#         factor=0.01,\n",
    "#         patience=5,\n",
    "#     ),\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         patience=5,\n",
    "#     ),\n",
    "#     # keras.callbacks.ModelCheckpoint(\n",
    "#     #     # filepath=checkpoint_filepath,\n",
    "#     #     # save_weights_only=True,\n",
    "#     #     monitor='val_loss',\n",
    "#     #     mode='min',\n",
    "#     #     # save_best_only=True\n",
    "#     # ),\n",
    "# ]\n",
    "\n",
    "# history = transformer.fit(train_ds,\n",
    "#                 epochs=EPOCHS,\n",
    "#                 callbacks=callbacks_list,\n",
    "#                 validation_data=val_ds)\n",
    "\n",
    "# # transformer.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Tftdj2gUkIfz",
    "outputId": "f6592644-ea01-48f9-d1c7-080f7649df17"
   },
   "outputs": [],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPSoMRIzYBPW",
    "outputId": "02a76757-85fb-4974-a923-f7b247ba6ddc"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "checkpoint_filepath = os.path.join(os.getcwd(), 'drive/My Drive/Datasets/checkpoint_1.weights.h5')\n",
    "\n",
    "# Compile the model with specified learning rate\n",
    "transformer.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "# Define callbacks\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5,  # Reduce LR if no improvement for 5 epochs\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,  # Stop training if no improvement for 5 epochs\n",
    "        verbose=1,\n",
    "        restore_best_weights=True  # Restore the best weights\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "with tf.device('gpu:0'):\n",
    "  history = transformer.fit(\n",
    "      train_ds,\n",
    "      epochs=EPOCHS,\n",
    "      callbacks=callbacks_list,\n",
    "      validation_data=val_ds\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zb-C10t5SwFi"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ve1ozHRGgD89"
   },
   "outputs": [],
   "source": [
    "# history.save('my_model_history.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "ZKdv9ch7Rbya",
    "outputId": "e9690df7-4911-4b43-b958-32b1e1e05362"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "d8mlYT4ISkuK",
    "outputId": "efaa89c1-d9c8-4ed9-ae65-ee177fee437a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))  # Adjust figure size if needed\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtOD2JFzcFTQ"
   },
   "source": [
    "# Testing the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwNvyuGHcFTQ"
   },
   "source": [
    "Let's translate a few random test sentences with our newly-trained Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wllho0aIcFTQ"
   },
   "outputs": [],
   "source": [
    "target_vocab = target_vectorization.get_vocabulary()\n",
    "target_index_lookup = dict(zip(range(len(target_vocab)), target_vocab))\n",
    "max_decoded_sentence_length = 30\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = target_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "# random_index = np.random.randint(0, len(test_df))\n",
    "# input_sentence = test_df[\"source\"].iloc[random_index]\n",
    "# print(input_sentence)\n",
    "# print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1TjB5rMNC7C",
    "outputId": "7f56667c-602a-4940-cc66-1d24e578e21a"
   },
   "outputs": [],
   "source": [
    "example = \"I live in Kathmandu.\"\n",
    "translation = decode_sequence(example)\n",
    "print(f\"'{example}' translated to - '{translation}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYt4ADha0urF",
    "outputId": "6e4c260b-1c99-4c20-fd9c-f01140af0f85"
   },
   "outputs": [],
   "source": [
    "example = \"The translation was correct.\"\n",
    "translation = decode_sequence(example)\n",
    "print(f\"'{example}' translated to - '{translation}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feoMgUjfmKAH",
    "outputId": "6b001095-e9ea-4b77-c67f-bc71a44c9d6b"
   },
   "outputs": [],
   "source": [
    "example = \"We completed the project\"\n",
    "translation = decode_sequence(example)\n",
    "print(f\"'{example}' translated to - '{translation}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNuOABU_0251",
    "outputId": "426fd026-2d7c-4352-bb02-7bbed0177aa0"
   },
   "outputs": [],
   "source": [
    "example = \"The result was good.\"\n",
    "translation = decode_sequence(example)\n",
    "print(f\"'{example}' translated to - '{translation}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5FqgZioPmty"
   },
   "source": [
    "# Evaluating the model using BLEU (Bilingual Evaluation Understandy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RThTccJJQJEq",
    "outputId": "5e2b82f4-bde0-4d06-f583-17fd7562e51b"
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-585kH_7PmQr",
    "outputId": "edf6a36a-5c69-4413-fca3-2ee66a389352"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "input_sentence, translated_sentence = test_df.iloc[np.random.randint(0, len(test_df))]\n",
    "\n",
    "reference = translated_sentence.split()\n",
    "hypothesis = decode_sequence(input_sentence).split()\n",
    "\n",
    "BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, weights = (0.5, 0.5))\n",
    "\n",
    "print('BLEU score -> {}'.format(BLEUscore))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 592212,
     "sourceId": 1067156,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
